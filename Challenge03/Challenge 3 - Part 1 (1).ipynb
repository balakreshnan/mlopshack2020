{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set experiment folder\n",
    "\n",
    "**NOTE:** This template notebook assume you have succcessfully ran through Challenge 2. You should already have a train.py, driver_training.py, along with a parameters.json in an experiments folder. Using this template, it'll create another script file for registrating the model called registration.py that'll be added to the experiment folder (defined in the cell below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder for the experiment files used in Challenge 2\n",
    "training_folder = 'driver-training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## register_model.py\n",
    "This file loads the model from where it was saved, and then registers it in the workspace.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting driver-training/register_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/register_model.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "import joblib\n",
    "from azureml.core import Workspace, Model, Run\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_folder', type=str, dest='model_folder', default=\"driver_model\", help='model location')\n",
    "args = parser.parse_args()\n",
    "model_folder = args.model_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Load the model\n",
    "print(\"Loading model from \" + model_folder)\n",
    "model_file = model_folder + \"/driver_model.pkl\"\n",
    "model = joblib.load(model_file)\n",
    "\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'driver_model',\n",
    "               tags={'Training context':'Pipeline', 'AUC': run.get_metrics()['AUC']})\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure Machine Learning Pipeline to Run the Scripts as a Pipeline\n",
    "\n",
    "See [this tutorial](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/05-Creating_a_Pipeline.ipynb) for a starting point\n",
    "\n",
    "Use the scikit-learn and lightgbm conda packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Verify that the compute cluster exists\n",
    "# If not, create it\n",
    "## TODO\n",
    "cluster_name = \"team5hacker2\"\n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4,\n",
    "                                                           idle_seconds_before_scaledown=1800)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "pipeline_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "# Let Azure ML manage dependencies by setting user_managed_dependencies to False\n",
    "# Use docker containers by setting docker.enabled to True \n",
    "## TODO\n",
    "\n",
    "# Create a the pip and conda package dependencies\n",
    "## TODO\n",
    "\n",
    "# Add the package dependencies to the Python environment for the experiment\n",
    "## TODO\n",
    "\n",
    "# Register the environment \n",
    "## TODO\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "## TODO\n",
    "\n",
    "# Assign the target of the runconfig object to the cluster created above  \n",
    "## TODO\n",
    "\n",
    "# Assign the environment of the runconfig object to the registered environment\n",
    "## TODO\n",
    "\n",
    "#print (\"Run configuration created.\")\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "diabetes_env = Environment(\"driver-pipeline-env\")\n",
    "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "diabetes_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies\n",
    "driver_packages = CondaDependencies.create(conda_packages=['scikit-learn','pandas','lightgbm'],\n",
    "                                             pip_packages=['azureml-sdk'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "diabetes_env.python.conda_dependencies = driver_packages\n",
    "\n",
    "# Register the environment (just in case you want to use it again)\n",
    "diabetes_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'driver-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "## TODO\n",
    "\n",
    "# Create Estimator to train the model as in Challenge 2\n",
    "## TODO\n",
    "\n",
    "# Create Step 1, which runs the estimator to train the model\n",
    "## TODO\n",
    "\n",
    "# Create Step 2, which runs the model registration script\n",
    "## TODO\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"driver dataset\")\n",
    "\n",
    "training_folder = 'driver-training'\n",
    "experiment_folder = 'driver-training'\n",
    "\n",
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "model_folder = PipelineData(\"model_folder\", datastore=ws.get_default_datastore())\n",
    "\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                        compute_target = pipeline_cluster,\n",
    "                        environment_definition=pipeline_run_config.environment,\n",
    "                        entry_script='driver_training.py')\n",
    "\n",
    "# Step 1, run the estimator to train the model\n",
    "#driver_training\n",
    "train_step = EstimatorStep(name = \"Train Model\",\n",
    "                           estimator=estimator, \n",
    "                           estimator_entry_script_arguments=['--output_folder', model_folder],\n",
    "                           inputs=[diabetes_ds.as_named_input('driver_train')],\n",
    "                           outputs=[model_folder],\n",
    "                           compute_target = pipeline_cluster,\n",
    "                           allow_reuse = True)\n",
    "\n",
    "# Step 2, run the model registration script\n",
    "register_step = PythonScriptStep(name = \"Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"register_model.py\",\n",
    "                                arguments = ['--model_folder', model_folder],\n",
    "                                inputs=[model_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "\n",
    "print(\"Pipeline steps defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n",
      "Created step Train Model [b803530e][0d0cdd40-8c44-40d6-aa92-70805503dc33], (This step will run and generate new outputs)\n",
      "Created step Register Model [df754df7][ad11b888-772c-4195-8c75-f5e75e897636], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 439d930b-64d2-423d-9ef6-1d5a0c48558a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/439d930b-64d2-423d-9ef6-1d5a0c48558a?wsid=/subscriptions/b4f30574-19b5-4753-926d-877888e82fc4/resourcegroups/oh-dsdata-data/workspaces/team5ws\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08206a1106a94020ad207d7244ec1fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"loading\": true}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 439d930b-64d2-423d-9ef6-1d5a0c48558a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/439d930b-64d2-423d-9ef6-1d5a0c48558a?wsid=/subscriptions/b4f30574-19b5-4753-926d-877888e82fc4/resourcegroups/oh-dsdata-data/workspaces/team5ws\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 5aa95051-8b4d-4b23-b216-b95c271792cb\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/5aa95051-8b4d-4b23-b216-b95c271792cb?wsid=/subscriptions/b4f30574-19b5-4753-926d-877888e82fc4/resourcegroups/oh-dsdata-data/workspaces/team5ws\n",
      "StepRun( Train Model ) Status: NotStarted\n",
      "StepRun( Train Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt\n",
      "========================================================================================================================\n",
      "2020-05-27T18:38:46Z Starting output-watcher...\n",
      "2020-05-27T18:38:46Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "6188dacf086b09fa58208ddfe7a05e64bc5d02b1dcbb72a05af7869171ee7b67\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-05-27T18:38:48.835037\n",
      "Starting job preparation. Current time:2020-05-27T18:38:49.771405\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 27e83d4c-e027-42e5-85e9-ed1f77fdfd65\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 56\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-05-27T18:38:57.128884\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2020/05/27 18:39:00 Instrumentation Key Is Empty Skipping App Insight Logger\n",
      "Entering context manager injector. Current time:2020-05-27T18:39:02.264813\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 119\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ driver_training.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/team5ws/azureml/5aa95051-8b4d-4b23-b216-b95c271792cb/mounts/workspaceblobstore/azureml/5aa95051-8b4d-4b23-b216-b95c271792cb/model_folder']\n",
      "After variable expansion, calling script [ driver_training.py ] with arguments: ['--output_folder', '/mnt/batch/tasks/shared/LS_root/jobs/team5ws/azureml/5aa95051-8b4d-4b23-b216-b95c271792cb/mounts/workspaceblobstore/azureml/5aa95051-8b4d-4b23-b216-b95c271792cb/model_folder']\n",
      "\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[1]\tvalid_0's auc: 0.595844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.605252\n",
      "[3]\tvalid_0's auc: 0.612784\n",
      "[4]\tvalid_0's auc: 0.61756\n",
      "[5]\tvalid_0's auc: 0.620129\n",
      "[6]\tvalid_0's auc: 0.622447\n",
      "[7]\tvalid_0's auc: 0.622163\n",
      "[8]\tvalid_0's auc: 0.622112\n",
      "[9]\tvalid_0's auc: 0.622581\n",
      "[10]\tvalid_0's auc: 0.622278\n",
      "[11]\tvalid_0's auc: 0.622433\n",
      "[12]\tvalid_0's auc: 0.623423\n",
      "[13]\tvalid_0's auc: 0.623618\n",
      "[14]\tvalid_0's auc: 0.62414\n",
      "[15]\tvalid_0's auc: 0.624421\n",
      "[16]\tvalid_0's auc: 0.624512\n",
      "[17]\tvalid_0's auc: 0.625151\n",
      "[18]\tvalid_0's auc: 0.62529\n",
      "[19]\tvalid_0's auc: 0.625437\n",
      "[20]\tvalid_0's auc: 0.62563\n",
      "[21]\tvalid_0's auc: 0.625963\n",
      "[22]\tvalid_0's auc: 0.626147\n",
      "[23]\tvalid_0's auc: 0.626383\n",
      "[24]\tvalid_0's auc: 0.626618\n",
      "[25]\tvalid_0's auc: 0.626586\n",
      "[26]\tvalid_0's auc: 0.626839\n",
      "[27]\tvalid_0's auc: 0.626972\n",
      "[28]\tvalid_0's auc: 0.626935\n",
      "[29]\tvalid_0's auc: 0.626946\n",
      "[30]\tvalid_0's auc: 0.627204\n",
      "[31]\tvalid_0's auc: 0.627252\n",
      "[32]\tvalid_0's auc: 0.627302\n",
      "[33]\tvalid_0's auc: 0.627249\n",
      "[34]\tvalid_0's auc: 0.627517\n",
      "[35]\tvalid_0's auc: 0.627755\n",
      "[36]\tvalid_0's auc: 0.62766\n",
      "[37]\tvalid_0's auc: 0.627483\n",
      "[38]\tvalid_0's auc: 0.627578\n",
      "[39]\tvalid_0's auc: 0.627433\n",
      "[40]\tvalid_0's auc: 0.627573\n",
      "[41]\tvalid_0's auc: 0.627908\n",
      "[42]\tvalid_0's auc: 0.627968\n",
      "[43]\tvalid_0's auc: 0.628082\n",
      "[44]\tvalid_0's auc: 0.628398\n",
      "[45]\tvalid_0's auc: 0.628763\n",
      "[46]\tvalid_0's auc: 0.629011\n",
      "[47]\tvalid_0's auc: 0.629321\n",
      "[48]\tvalid_0's auc: 0.629341\n",
      "[49]\tvalid_0's auc: 0.629353\n",
      "[50]\tvalid_0's auc: 0.629291\n",
      "[51]\tvalid_0's auc: 0.629447\n",
      "[52]\tvalid_0's auc: 0.629507\n",
      "[53]\tvalid_0's auc: 0.629725\n",
      "[54]\tvalid_0's auc: 0.630048\n",
      "[55]\tvalid_0's auc: 0.630085\n",
      "[56]\tvalid_0's auc: 0.630035\n",
      "[57]\tvalid_0's auc: 0.630236\n",
      "[58]\tvalid_0's auc: 0.630486\n",
      "[59]\tvalid_0's auc: 0.630663\n",
      "[60]\tvalid_0's auc: 0.630787\n",
      "[61]\tvalid_0's auc: 0.630932\n",
      "[62]\tvalid_0's auc: 0.631004\n",
      "[63]\tvalid_0's auc: 0.631161\n",
      "[64]\tvalid_0's auc: 0.631407\n",
      "[65]\tvalid_0's auc: 0.631408\n",
      "[66]\tvalid_0's auc: 0.631515\n",
      "[67]\tvalid_0's auc: 0.631631\n",
      "[68]\tvalid_0's auc: 0.631628\n",
      "[69]\tvalid_0's auc: 0.631703\n",
      "[70]\tvalid_0's auc: 0.631781\n",
      "[71]\tvalid_0's auc: 0.631786\n",
      "[72]\tvalid_0's auc: 0.631779\n",
      "[73]\tvalid_0's auc: 0.632022\n",
      "[74]\tvalid_0's auc: 0.632086\n",
      "[75]\tvalid_0's auc: 0.632107\n",
      "[76]\tvalid_0's auc: 0.632201\n",
      "[77]\tvalid_0's auc: 0.632165\n",
      "[78]\tvalid_0's auc: 0.632335\n",
      "[79]\tvalid_0's auc: 0.632446\n",
      "[80]\tvalid_0's auc: 0.63254\n",
      "[81]\tvalid_0's auc: 0.632654\n",
      "[82]\tvalid_0's auc: 0.632663\n",
      "[83]\tvalid_0's auc: 0.632811\n",
      "[84]\tvalid_0's auc: 0.63291\n",
      "[85]\tvalid_0's auc: 0.632993\n",
      "[86]\tvalid_0's auc: 0.632962\n",
      "[87]\tvalid_0's auc: 0.632941\n",
      "[88]\tvalid_0's auc: 0.633062\n",
      "[89]\tvalid_0's auc: 0.633144\n",
      "[90]\tvalid_0's auc: 0.633242\n",
      "[91]\tvalid_0's auc: 0.633336\n",
      "[92]\tvalid_0's auc: 0.633453\n",
      "[93]\tvalid_0's auc: 0.633556\n",
      "[94]\tvalid_0's auc: 0.633648\n",
      "[95]\tvalid_0's auc: 0.633762\n",
      "[96]\tvalid_0's auc: 0.633831\n",
      "[97]\tvalid_0's auc: 0.633922\n",
      "[98]\tvalid_0's auc: 0.633908\n",
      "[99]\tvalid_0's auc: 0.633958\n",
      "[100]\tvalid_0's auc: 0.634122\n",
      "[101]\tvalid_0's auc: 0.634278\n",
      "[102]\tvalid_0's auc: 0.634301\n",
      "[103]\tvalid_0's auc: 0.634313\n",
      "[104]\tvalid_0's auc: 0.634366\n",
      "[105]\tvalid_0's auc: 0.634497\n",
      "[106]\tvalid_0's auc: 0.634442\n",
      "[107]\tvalid_0's auc: 0.634487\n",
      "[108]\tvalid_0's auc: 0.634578\n",
      "[109]\tvalid_0's auc: 0.634676\n",
      "[110]\tvalid_0's auc: 0.63479\n",
      "[111]\tvalid_0's auc: 0.634846\n",
      "[112]\tvalid_0's auc: 0.634918\n",
      "[113]\tvalid_0's auc: 0.63501\n",
      "[114]\tvalid_0's auc: 0.634965\n",
      "[115]\tvalid_0's auc: 0.635029\n",
      "[116]\tvalid_0's auc: 0.635077\n",
      "[117]\tvalid_0's auc: 0.635075\n",
      "[118]\tvalid_0's auc: 0.6352\n",
      "[119]\tvalid_0's auc: 0.635215\n",
      "[120]\tvalid_0's auc: 0.635231\n",
      "[121]\tvalid_0's auc: 0.635276\n",
      "[122]\tvalid_0's auc: 0.635268\n",
      "[123]\tvalid_0's auc: 0.635221\n",
      "[124]\tvalid_0's auc: 0.635178\n",
      "[125]\tvalid_0's auc: 0.635221\n",
      "[126]\tvalid_0's auc: 0.635288\n",
      "[127]\tvalid_0's auc: 0.635345\n",
      "[128]\tvalid_0's auc: 0.635348\n",
      "[129]\tvalid_0's auc: 0.635414\n",
      "[130]\tvalid_0's auc: 0.635418\n",
      "[131]\tvalid_0's auc: 0.635352\n",
      "[132]\tvalid_0's auc: 0.635402\n",
      "[133]\tvalid_0's auc: 0.635497\n",
      "[134]\tvalid_0's auc: 0.635545\n",
      "[135]\tvalid_0's auc: 0.63565\n",
      "[136]\tvalid_0's auc: 0.635622\n",
      "[137]\tvalid_0's auc: 0.635664\n",
      "[138]\tvalid_0's auc: 0.635781\n",
      "[139]\tvalid_0's auc: 0.635735\n",
      "[140]\tvalid_0's auc: 0.635719\n",
      "[141]\tvalid_0's auc: 0.635815\n",
      "[142]\tvalid_0's auc: 0.635799\n",
      "[143]\tvalid_0's auc: 0.63583\n",
      "[144]\tvalid_0's auc: 0.635898\n",
      "[145]\tvalid_0's auc: 0.635924\n",
      "[146]\tvalid_0's auc: 0.635885\n",
      "[147]\tvalid_0's auc: 0.635919\n",
      "[148]\tvalid_0's auc: 0.63598\n",
      "[149]\tvalid_0's auc: 0.636035\n",
      "[150]\tvalid_0's auc: 0.636087\n",
      "[151]\tvalid_0's auc: 0.636139\n",
      "[152]\tvalid_0's auc: 0.63617\n",
      "[153]\tvalid_0's auc: 0.636128\n",
      "[154]\tvalid_0's auc: 0.636096\n",
      "[155]\tvalid_0's auc: 0.636206\n",
      "[156]\tvalid_0's auc: 0.636259\n",
      "[157]\tvalid_0's auc: 0.636289\n",
      "[158]\tvalid_0's auc: 0.636283\n",
      "[159]\tvalid_0's auc: 0.636287\n",
      "[160]\tvalid_0's auc: 0.636293\n",
      "[161]\tvalid_0's auc: 0.636324\n",
      "[162]\tvalid_0's auc: 0.63633\n",
      "[163]\tvalid_0's auc: 0.636367\n",
      "[164]\tvalid_0's auc: 0.636438\n",
      "[165]\tvalid_0's auc: 0.636483\n",
      "[166]\tvalid_0's auc: 0.636577\n",
      "[167]\tvalid_0's auc: 0.636645\n",
      "[168]\tvalid_0's auc: 0.63659\n",
      "[169]\tvalid_0's auc: 0.636595\n",
      "[170]\tvalid_0's auc: 0.636672\n",
      "[171]\tvalid_0's auc: 0.636719\n",
      "[172]\tvalid_0's auc: 0.636755\n",
      "[173]\tvalid_0's auc: 0.636833\n",
      "[174]\tvalid_0's auc: 0.636908\n",
      "[175]\tvalid_0's auc: 0.636929\n",
      "[176]\tvalid_0's auc: 0.636928\n",
      "[177]\tvalid_0's auc: 0.636962\n",
      "[178]\tvalid_0's auc: 0.636969\n",
      "[179]\tvalid_0's auc: 0.636995\n",
      "[180]\tvalid_0's auc: 0.637059\n",
      "[181]\tvalid_0's auc: 0.637089\n",
      "[182]\tvalid_0's auc: 0.637085\n",
      "[183]\tvalid_0's auc: 0.637121\n",
      "[184]\tvalid_0's auc: 0.637131\n",
      "[185]\tvalid_0's auc: 0.637133\n",
      "[186]\tvalid_0's auc: 0.637144\n",
      "[187]\tvalid_0's auc: 0.637189\n",
      "[188]\tvalid_0's auc: 0.637173\n",
      "[189]\tvalid_0's auc: 0.63719\n",
      "[190]\tvalid_0's auc: 0.637205\n",
      "[191]\tvalid_0's auc: 0.637131\n",
      "[192]\tvalid_0's auc: 0.637159\n",
      "[193]\tvalid_0's auc: 0.637185\n",
      "[194]\tvalid_0's auc: 0.63719\n",
      "[195]\tvalid_0's auc: 0.637224\n",
      "[196]\tvalid_0's auc: 0.637219\n",
      "[197]\tvalid_0's auc: 0.637193\n",
      "[198]\tvalid_0's auc: 0.637297\n",
      "[199]\tvalid_0's auc: 0.637329\n",
      "[200]\tvalid_0's auc: 0.6373\n",
      "[201]\tvalid_0's auc: 0.637257\n",
      "[202]\tvalid_0's auc: 0.637253\n",
      "[203]\tvalid_0's auc: 0.637261\n",
      "[204]\tvalid_0's auc: 0.637252\n",
      "[205]\tvalid_0's auc: 0.637273\n",
      "[206]\tvalid_0's auc: 0.637297\n",
      "[207]\tvalid_0's auc: 0.637345\n",
      "[208]\tvalid_0's auc: 0.637401\n",
      "[209]\tvalid_0's auc: 0.637456\n",
      "[210]\tvalid_0's auc: 0.637392\n",
      "[211]\tvalid_0's auc: 0.637373\n",
      "[212]\tvalid_0's auc: 0.63741\n",
      "[213]\tvalid_0's auc: 0.637459\n",
      "[214]\tvalid_0's auc: 0.637496\n",
      "[215]\tvalid_0's auc: 0.637539\n",
      "[216]\tvalid_0's auc: 0.637546\n",
      "[217]\tvalid_0's auc: 0.637535\n",
      "[218]\tvalid_0's auc: 0.637511\n",
      "[219]\tvalid_0's auc: 0.6375\n",
      "[220]\tvalid_0's auc: 0.637502\n",
      "[221]\tvalid_0's auc: 0.637493\n",
      "[222]\tvalid_0's auc: 0.637431\n",
      "[223]\tvalid_0's auc: 0.637413\n",
      "[224]\tvalid_0's auc: 0.637421\n",
      "[225]\tvalid_0's auc: 0.637368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt\n",
      "===============================================================================================================\n",
      "Entering job release. Current time:2020-05-27T18:39:19.843872\n",
      "Starting job release. Current time:2020-05-27T18:39:21.723951\n",
      "Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 184\n",
      "Entering context manager injector. Current time:2020-05-27T18:39:21.745435\n",
      "Job release is complete. Current time:2020-05-27T18:39:24.011664\n",
      "\n",
      "StepRun(Train Model) Execution Summary\n",
      "=======================================\n",
      "StepRun( Train Model ) Status: Finished\n",
      "{'runId': '5aa95051-8b4d-4b23-b216-b95c271792cb', 'target': 'team5hacker2', 'status': 'Completed', 'startTimeUtc': '2020-05-27T18:38:50.23993Z', 'endTimeUtc': '2020-05-27T18:39:25.589476Z', 'properties': {'azureml.runsource': 'azureml.StepRun', 'ContentSnapshotId': '27e83d4c-e027-42e5-85e9-ed1f77fdfd65', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '0d0cdd40-8c44-40d6-aa92-70805503dc33', 'azureml.pipelinerunid': '439d930b-64d2-423d-9ef6-1d5a0c48558a', '_azureml.ComputeTargetType': 'amlcompute', 'AzureML.DerivedImageName': 'azureml/azureml_be3b8acd74e860626700cd80d2081f15', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '4a0c1bcb-ac13-402c-82be-071950386e3b'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'driver_train', 'mechanism': 'Direct'}}], 'runDefinition': {'script': 'driver_training.py', 'useAbsolutePath': False, 'arguments': ['--output_folder', '$AZUREML_DATAREFERENCE_model_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'team5hacker2', 'dataReferences': {'model_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/5aa95051-8b4d-4b23-b216-b95c271792cb/model_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'driver_train': {'dataLocation': {'dataset': {'id': '4a0c1bcb-ac13-402c-82be-071950386e3b'}, 'dataPath': None}, 'createOutputDirectories': False, 'mechanism': 'Direct', 'environmentVariableName': 'driver_train', 'pathOnCompute': None, 'overwrite': False}}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'environment': {'name': 'Experiment driver-training-pipeline Environment', 'version': 'Autosave_2020-05-27T12:34:24Z_9a78c0b7', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['--index-url https://azuremlsdktestpypi.azureedge.net/sdk-release/Candidate/604C89A437BA41BD942B4F46D9A3591D', '--extra-index-url https://pypi.python.org/simple', 'azureml-sdk']}, 'scikit-learn', 'pandas', 'lightgbm'], 'name': 'azureml_37b88f121c458d7f3acf72946d01e394'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04', 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': True, 'shmSize': '1g'}, 'spark': {'repositories': ['[]'], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs']}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '1g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'itpCompute': {'configuration': {}}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/azureml-logs/55_azureml-execution-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt?sv=2019-02-02&sr=b&sig=j4sqjscyQGWWHRrbQM8z%2FN%2BUXJRIzSkgHm7g%2Bk%2Fp%2FGk%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'azureml-logs/65_job_prep-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/azureml-logs/65_job_prep-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt?sv=2019-02-02&sr=b&sig=lPikuSlttry3VdPt68%2FZmWxLAHFmOB7iG3ylP4GjfaU%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=qPuyWKrgLIQv6OnaGkqyfmVkyXZCKXQmE4UE4Hx9mj8%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'azureml-logs/75_job_post-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/azureml-logs/75_job_post-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt?sv=2019-02-02&sr=b&sig=%2FE1Ky7XFzA6hwwt4sy%2BxPYNyWk795d4k3xopu2oZ6NE%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'azureml-logs/process_info.json': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=4D22uhky3beMMqy10npd2DwTiT22dPmNaiemNgX3oL4%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'azureml-logs/process_status.json': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=MTvipX3NXhHSU4usvTwdIg4MVfidUpX3OxU8AP1gS8Q%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'logs/azureml/119_azureml.log': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/logs/azureml/119_azureml.log?sv=2019-02-02&sr=b&sig=AhZT%2BDzh%2BN9zKUFgXTdRjLK77vZGT1yrEIjcUu0E57U%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=I7LNde%2FTSxwR4YTQCJRKTiTTXZ4q5gO8e%2FnnqAuzjS0%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=kQItA%2FmJMIuVYSNrL6ImH4PZE4YbYHRf0C8%2Fe0PIkB4%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=uOsmsojmygBwjT54zzRH0Y3gepUGOB6MSZsgnd4a9Xo%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=57vyWSeeGAL%2FWzxM49CXzLXjqvp3NBAAd9SJ4IjnoFw%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.5aa95051-8b4d-4b23-b216-b95c271792cb/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=KBTeXuwQUE4gmnKbm%2BP%2BxT8lnOnvwfC2lo8C7RVSNXw%3D&st=2020-05-27T18%3A29%3A30Z&se=2020-05-28T02%3A39%3A30Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "StepRunId: fa4bb60e-2610-40b1-b1e9-4dbdabc8baaa\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/driver-training-pipeline/runs/fa4bb60e-2610-40b1-b1e9-4dbdabc8baaa?wsid=/subscriptions/b4f30574-19b5-4753-926d-877888e82fc4/resourcegroups/oh-dsdata-data/workspaces/team5ws\n",
      "StepRun( Register Model ) Status: NotStarted\n",
      "StepRun( Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt\n",
      "========================================================================================================================\n",
      "2020-05-27T18:40:03Z Starting output-watcher...\n",
      "2020-05-27T18:40:03Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "cf828009ad5ba2abd3cb977290ee0162d819b5f3fbfa94629a4a706d64a9e939\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_244146e7829ac6ee5a99b5bbd5052c6e933b7cf74a474464457f13f958085e74_d.txt\n",
      "===============================================================================================================\n",
      "Entering job preparation. Current time:2020-05-27T18:40:05.579709\n",
      "Starting job preparation. Current time:2020-05-27T18:40:06.521114\n",
      "Extracting the control code.\n",
      "fetching and extracting the control code on master node.\n",
      "Retrieving project from snapshot: 27e83d4c-e027-42e5-85e9-ed1f77fdfd65\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 56\n",
      "Starting project file download.\n",
      "Finished project file download.\n",
      "downloadDataStore - Download from datastores if requested.\n",
      "Entering context manager injector. Current time:2020-05-27T18:40:12.982487\n",
      "Acquired lockfile /tmp/fa4bb60e-2610-40b1-b1e9-4dbdabc8baaa-datastore.lock to downloading input data references\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline, which contains Step 1 & 2\n",
    "## TODO\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "## TODO\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [train_step, register_step]\n",
    "pipeline = Pipeline(workspace = ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")\n",
    "\n",
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace = ws, name = 'driver-training-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_model version: 2\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "driver_model version: 1\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "driver_model.pkl version: 12\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "driver_model.pkl version: 11\n",
      "\t auc : 0.6380025131414137\n",
      "\n",
      "\n",
      "driver_model.pkl version: 10\n",
      "\t metrics : {'driver-training_1590531244_e6526452': {'learning_rate': 0.04, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'sub_feature': 0.7, 'num_leaves': 60, 'min_data': 100, 'verbose': 0, 'min_hessian': 1, 'auc': 0.6380025131414137}}\n",
      "\n",
      "\n",
      "driver_model.pkl version: 9\n",
      "\t metrics : {'driver-training_1590530540_fe469c8e': {'learning_rate': 0.02, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'num_leaves': 60, 'sub_feature': 0.7, 'verbose': 0, 'min_hessian': 1, 'min_data': 100, 'auc': 0.6377511613946426}}\n",
      "\n",
      "\n",
      "driver_model.pkl version: 8\n",
      "\t auc : {'driver-training_1590530540_fe469c8e': {'learning_rate': 0.02, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'num_leaves': 60, 'sub_feature': 0.7, 'verbose': 0, 'min_hessian': 1, 'min_data': 100, 'auc': 0.6377511613946426}}\n",
      "\n",
      "\n",
      "driver_model.pkl version: 7\n",
      "\t auc : auc\n",
      "\n",
      "\n",
      "driver_model.pkl version: 6\n",
      "\t auc : a\n",
      "\n",
      "\n",
      "driver_model.pkl version: 5\n",
      "\t auc : auc\n",
      "\n",
      "\n",
      "driver_model.pkl version: 4\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "driver_model.pkl version: 3\n",
      "\n",
      "\n",
      "driver_model.pkl version: 2\n",
      "\n",
      "\n",
      "driver_model.pkl version: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the model name, version, tag, and properties\n",
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
