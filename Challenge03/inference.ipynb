{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.5.0 to work with team5ws\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_model version: 1\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "driver_model.pkl version: 12\n",
      "\t auc : 0.6377511613946426\n",
      "\n",
      "\n",
      "driver_model.pkl version: 11\n",
      "\t auc : 0.6380025131414137\n",
      "\n",
      "\n",
      "driver_model.pkl version: 10\n",
      "\t metrics : {'driver-training_1590531244_e6526452': {'learning_rate': 0.04, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'sub_feature': 0.7, 'num_leaves': 60, 'min_data': 100, 'verbose': 0, 'min_hessian': 1, 'auc': 0.6380025131414137}}\n",
      "\n",
      "\n",
      "driver_model.pkl version: 9\n",
      "\t metrics : {'driver-training_1590530540_fe469c8e': {'learning_rate': 0.02, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'num_leaves': 60, 'sub_feature': 0.7, 'verbose': 0, 'min_hessian': 1, 'min_data': 100, 'auc': 0.6377511613946426}}\n",
      "\n",
      "\n",
      "driver_model.pkl version: 8\n",
      "\t auc : {'driver-training_1590530540_fe469c8e': {'learning_rate': 0.02, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'num_leaves': 60, 'sub_feature': 0.7, 'verbose': 0, 'min_hessian': 1, 'min_data': 100, 'auc': 0.6377511613946426}}\n",
      "\n",
      "\n",
      "driver_model.pkl version: 7\n",
      "\t auc : auc\n",
      "\n",
      "\n",
      "driver_model.pkl version: 6\n",
      "\t auc : a\n",
      "\n",
      "\n",
      "driver_model.pkl version: 5\n",
      "\t auc : auc\n",
      "\n",
      "\n",
      "driver_model.pkl version: 4\n",
      "\t Training context : Pipeline\n",
      "\n",
      "\n",
      "driver_model.pkl version: 3\n",
      "\n",
      "\n",
      "driver_model.pkl version: 2\n",
      "\n",
      "\n",
      "driver_model.pkl version: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_model version 1\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['driver_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'driver_service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing driver_service/score_driver.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $folder_name/score_driver.py\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('driver_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    #classnames = ['not-diabetic', 'diabetic']\n",
    "    #predicted_classes = []\n",
    "    #for prediction in predictions:\n",
    "    #    predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return {\"result\": predictions.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in driver_service/driver_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "- lightgbm\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "myenv.add_conda_package(\"lightgbm\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = folder_name + \"/driver_env.yml\"\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.................................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   source_directory = folder_name,\n",
    "                                   entry_script=\"score_driver.py\",\n",
    "                                   conda_file=\"driver_env.yml\")\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"driver-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "2020-05-27T15:31:04,691018816+00:00 - rsyslog/run \n",
      "2020-05-27T15:31:04,694580278+00:00 - iot-server/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_06c16b148b04e8226cfe58e6ee379ca1/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-05-27T15:31:04,710823703+00:00 - nginx/run \n",
      "2020-05-27T15:31:04,710463807+00:00 - gunicorn/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-05-27T15:31:04,843974767+00:00 - iot-server/finish 1 0\n",
      "2020-05-27T15:31:04,845398452+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "Users's init has completed successfully\n",
      "Scoring timeout is found from os.environ: 60000 ms\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [27/May/2020:15:31:24 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "Swagger file not present\n",
      "404\n",
      "127.0.0.1 - - [27/May/2020:15:31:28 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "127.0.0.1 - - [27/May/2020:15:33:42 +0000] \"POST /api/events/raw HTTP/1.0\" 404 232 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.state)\n",
    "print(service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drivers-service5\n",
      "test-aci-deployment-for-driver\n",
      "driver-service\n"
     ]
    }
   ],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\n",
      "Response Code: 502\n",
      "Headers: {'Connection': 'keep-alive', 'Content-Length': '49', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Wed, 27 May 2020 18:05:13 GMT', 'Server': 'nginx/1.10.3 (Ubuntu)', 'X-Ms-Request-Id': '0829c6af-7b03-4e1a-8d70-dffc25306753', 'X-Ms-Run-Function-Failed': 'True'}\n",
      "Content: b\"Object of type 'ndarray' is not JSON serializable\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drivers: [7, 0, 2, 2, 5, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 11, 0, 1, 0, 0.7, 0.2, 0.7180703307999999, 10, 1, -1, 0, 1, 4, 1, 0, 0, 1, 12, 2, 0.4, 0.8836789178, 0.3708099244, 3.6055512755000003, 0.6, 0.5, 0.2, 3, 1, 10, 1, 10, 1, 5, 9, 1, 5, 8, 0, 1, 1, 0, 0, 1]\n",
      "input:  {\"data\": [[7, 0, 2, 2, 5, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 11, 0, 1, 0, 0.7, 0.2, 0.7180703307999999, 10, 1, -1, 0, 1, 4, 1, 0, 0, 1, 12, 2, 0.4, 0.8836789178, 0.3708099244, 3.6055512755000003, 0.6, 0.5, 0.2, 3, 1, 10, 1, 10, 1, 5, 9, 1, 5, 8, 0, 1, 1, 0, 0, 1], [9, 0, 1, 1, 7, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0.8, 0.4, 0.7660776723, 11, 1, -1, 0, -1, 11, 1, 1, 2, 1, 19, 3, 0.316227766, 0.6188165191, 0.3887158345, 2.4494897428, 0.3, 0.1, 0.3, 2, 1, 9, 5, 8, 1, 7, 3, 1, 1, 9, 0, 1, 1, 0, 1, 0], [13, 0, 5, 4, 9, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 12, 1, 0, 0, 0.0, 0.0, -1.0, 7, 1, -1, 0, -1, 14, 1, 1, 2, 1, 60, 1, 0.316227766, 0.6415857163, 0.34727510710000004, 3.3166247904, 0.5, 0.7, 0.1, 2, 2, 9, 1, 8, 2, 7, 4, 2, 7, 7, 0, 1, 1, 0, 1, 0]]}\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\nResponse Code: 502\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '49', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Wed, 27 May 2020 18:05:13 GMT', 'Server': 'nginx/1.10.3 (Ubuntu)', 'X-Ms-Request-Id': '0829c6af-7b03-4e1a-8d70-dffc25306753', 'X-Ms-Run-Function-Failed': 'True'}\nContent: b\"Object of type 'ndarray' is not JSON serializable\"\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\\nResponse Code: 502\\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '49', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Wed, 27 May 2020 18:05:13 GMT', 'Server': 'nginx/1.10.3 (Ubuntu)', 'X-Ms-Request-Id': '0829c6af-7b03-4e1a-8d70-dffc25306753', 'X-Ms-Run-Function-Failed': 'True'}\\nContent: b\\\"Object of type 'ndarray' is not JSON serializable\\\"\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-3a78e9e07cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Call the web service, passing the input data (the web service will also accept the data in binary format)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#predictions = service.run(input_data = input_json)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m#predictions = service.run(TEST_ROW)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/aci.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    405\u001b[0m                                       \u001b[0;34m'Headers: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     def update(self, image=None, tags=None, properties=None, description=None, auth_enabled=None, ssl_enabled=None,\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\nResponse Code: 502\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '49', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Wed, 27 May 2020 18:05:13 GMT', 'Server': 'nginx/1.10.3 (Ubuntu)', 'X-Ms-Request-Id': '0829c6af-7b03-4e1a-8d70-dffc25306753', 'X-Ms-Run-Function-Failed': 'True'}\nContent: b\"Object of type 'ndarray' is not JSON serializable\"\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from service. More information can be found by calling `.get_logs()` on the webservice object.\\nResponse Code: 502\\nHeaders: {'Connection': 'keep-alive', 'Content-Length': '49', 'Content-Type': 'text/html; charset=utf-8', 'Date': 'Wed, 27 May 2020 18:05:13 GMT', 'Server': 'nginx/1.10.3 (Ubuntu)', 'X-Ms-Request-Id': '0829c6af-7b03-4e1a-8d70-dffc25306753', 'X-Ms-Run-Function-Failed': 'True'}\\nContent: b\\\"Object of type 'ndarray' is not JSON serializable\\\"\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "#x_new = '{\"data\": [[0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],[4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]]}'\n",
    "#x_new = [[0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],\n",
    "#         [4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]]\n",
    "\n",
    "x_new = [[7,0,2,2,5,1,0,0,1,0,0,0,0,0,0,0,11,0,1,0,0.7,0.2,0.7180703307999999,10,1,-1,0,1,4,1,0,0,1,12,2,0.4,0.8836789178,0.3708099244,3.6055512755000003,0.6,0.5,0.2,3,1,10,1,10,1,5,9,1,5,8,0,1,1,0,0,1],\n",
    "[9,0,1,1,7,0,0,0,0,1,0,0,0,0,0,0,3,0,0,1,0.8,0.4,0.7660776723,11,1,-1,0,-1,11,1,1,2,1,19,3,0.316227766,0.6188165191,0.3887158345,2.4494897428,0.3,0.1,0.3,2,1,9,5,8,1,7,3,1,1,9,0,1,1,0,1,0],\n",
    "[13,0,5,4,9,1,0,0,0,1,0,0,0,0,0,0,12,1,0,0,0.0,0.0,-1.0,7,1,-1,0,-1,14,1,1,2,1,60,1,0.316227766,0.6415857163,0.34727510710000004,3.3166247904,0.5,0.7,0.1,2,2,9,1,8,2,7,4,2,7,7,0,1,1,0,1,0]]\n",
    "\n",
    "print ('Drivers: {}'.format(x_new[0]))\n",
    "\n",
    "#TEST_ROW = '{\"data\": [[0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],[4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]]}'\n",
    "TEST_ROW = '{\"data\": [[2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1],[1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1]]}'\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "print(\"input: \", str(input_json))\n",
    "\n",
    "#input_d = np.array(input_json)\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "#predictions = service.run(input_data = input_json)\n",
    "predictions = service.run(input_json)\n",
    "#predictions = service.run(TEST_ROW)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "#predicted_classes = json.loads(predictions)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://324d806e-50e3-4216-ab8a-5fee5947aaf4.westus2.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result:  <Response [502]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[0,1,8,1,0,0,1,0,0,0,0,0,0,0,12,1,0,0,0.5,0.3,0.610327781,7,1,-1,0,-1,1,1,1,2,1,65,1,0.316227766,0.669556409,0.352136337,3.464101615,0.1,0.8,0.6,1,1,6,3,6,2,9,1,1,1,12,0,1,1,0,0,1],\n",
    "         [4,2,5,1,0,0,0,0,1,0,0,0,0,0,5,1,0,0,0.9,0.5,0.771362431,4,1,-1,0,0,11,1,1,0,1,103,1,0.316227766,0.60632002,0.358329457,2.828427125,0.4,0.5,0.4,3,3,8,4,10,2,7,2,0,3,10,0,0,1,1,0,1]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "#predicted_json = json.loads(predictions.json())\n",
    "print(\"Test result: \", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
