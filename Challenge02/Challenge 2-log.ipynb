{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'driver-training/porto_seguro_safe_driver_prediction_train.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'driver-training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/porto_seguro_safe_driver_prediction_train.csv', os.path.join(training_folder, \"porto_seguro_safe_driver_prediction_train.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py\n",
    "This file defines the key functions required to train the model.  \n",
    "The file can be invoked with `python train.py` for development purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting driver-training/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/train.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm\n",
    "\n",
    "\n",
    "def split_data(data_df):\n",
    "    features = data_df.drop(['target', 'id'], axis=1)\n",
    "    labels = np.array(data_df['target'])\n",
    "    features_train, features_valid, labels_train, labels_valid = \\\n",
    "        train_test_split(features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "    train_data = lightgbm.Dataset(features_train, label=labels_train)\n",
    "    valid_data = lightgbm.Dataset(\n",
    "        features_valid,\n",
    "        label=labels_valid,\n",
    "        free_raw_data=False)\n",
    "    return (train_data, valid_data)\n",
    "\n",
    "\n",
    "def train_model(data, parameters):\n",
    "    model = lightgbm.train(parameters,\n",
    "                           data[0],\n",
    "                           valid_sets=data[1],\n",
    "                           num_boost_round=500,\n",
    "                           early_stopping_rounds=20)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model_metrics(model, data):\n",
    "    predictions = model.predict(data[1].data)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(data[1].label, predictions)\n",
    "    model_metrics = {\"auc\": (metrics.auc(fpr, tpr))}\n",
    "    print(model_metrics)\n",
    "    return model_metrics\n",
    "\n",
    "\n",
    "def main():\n",
    "    data_df = pd.read_csv('porto_seguro_safe_driver_prediction_train.csv')\n",
    "    parameters = {\n",
    "        'learning_rate': 0.02,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'sub_feature': 0.7,\n",
    "        'num_leaves': 60,\n",
    "        'min_data': 100,\n",
    "        'min_hessian': 1,\n",
    "        'verbose': 2\n",
    "    }\n",
    "    data = split_data(data_df)\n",
    "    model = train_model(data, parameters)\n",
    "    get_model_metrics(model, data)\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters.json\n",
    "This file will specify the parameters used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting driver-training/parameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/parameters.json\n",
    "{\n",
    "    \"training\":\n",
    "    {\n",
    "        \"learning_rate\": 0.04,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"sub_feature\": 0.7,\n",
    "        \"num_leaves\": 60,\n",
    "        \"min_data\": 100,\n",
    "        \"min_hessian\": 1,\n",
    "        \"verbose\": 0\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## driver_training.py\n",
    "This file will be the entry script when running an Azure ML context.  \n",
    "It calls the functions defined in train.py for data preparation and training, but reads parameters from a file, and logs output to the Azure ML context.  \n",
    "The file can be invoked with `python driver_training.py` for development purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting driver-training/driver_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $training_folder/driver_training.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "from azureml.core import Run\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Import functions from train.py\n",
    "from train import split_data, train_model, get_model_metrics\n",
    "\n",
    "# Get the output folder for the model from the '--output_folder' parameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--output_folder',\n",
    "    type=str,\n",
    "    dest='output_folder',\n",
    "    default=\"outputs\")\n",
    "args = parser.parse_args()\n",
    "output_folder = args.output_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the safe driver prediction dataset\n",
    "train_df = pd.read_csv('porto_seguro_safe_driver_prediction_train.csv')\n",
    "\n",
    "# Load the parameters for training the model from the file\n",
    "with open(\"parameters.json\") as f:\n",
    "    pars = json.load(f)\n",
    "    parameters = pars[\"training\"]\n",
    "\n",
    "# Log the parameters\n",
    "for k, v in parameters.items():\n",
    "    run.log(k, v)\n",
    "    \n",
    "data = split_data(train_df)\n",
    "model = train_model(data, parameters)\n",
    "model_metrics = get_model_metrics(model, data)\n",
    "\n",
    "run.log('auc',model_metrics['auc'])\n",
    "\n",
    "# Save the trained model to the output folder\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = output_folder + \"/driver_model.pkl\"\n",
    "joblib.dump(value=model, filename=output_path)\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use an Estimator to Run the Script as an Experiment\n",
    "\n",
    "See [this tutorial](https://github.com/MicrosoftDocs/mslearn-aml-labs/blob/master/02-Training_Models.ipynb) for a starting point\n",
    "\n",
    "Use the scikit-learn and lightgbm conda packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: driver-training_1590531244_e6526452\n",
      "Web View: https://ml.azure.com/experiments/driver-training/runs/driver-training_1590531244_e6526452?wsid=/subscriptions/b4f30574-19b5-4753-926d-877888e82fc4/resourcegroups/oh-dsdata-data/workspaces/team5ws\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Entering context manager injector. Current time:2020-05-26T22:14:13.976826\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 8\n",
      "Entering Run History Context Manager.\n",
      "Preparing to call script [ driver_training.py ] with arguments: []\n",
      "After variable expansion, calling script [ driver_training.py ] with arguments: []\n",
      "\n",
      "[LightGBM] [Warning] Starting from the 2.1.2 version, default value for the \"boost_from_average\" parameter in \"binary\" objective is true.\n",
      "This may cause significantly different results comparing to the previous versions of LightGBM.\n",
      "Try to set boost_from_average=false, if your old models produce bad results\n",
      "[1]\tvalid_0's auc: 0.595844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's auc: 0.608461\n",
      "[3]\tvalid_0's auc: 0.614317\n",
      "[4]\tvalid_0's auc: 0.618862\n",
      "[5]\tvalid_0's auc: 0.622121\n",
      "[6]\tvalid_0's auc: 0.624124\n",
      "[7]\tvalid_0's auc: 0.623113\n",
      "[8]\tvalid_0's auc: 0.623201\n",
      "[9]\tvalid_0's auc: 0.623895\n",
      "[10]\tvalid_0's auc: 0.623983\n",
      "[11]\tvalid_0's auc: 0.624325\n",
      "[12]\tvalid_0's auc: 0.625393\n",
      "[13]\tvalid_0's auc: 0.62544\n",
      "[14]\tvalid_0's auc: 0.625896\n",
      "[15]\tvalid_0's auc: 0.626046\n",
      "[16]\tvalid_0's auc: 0.62602\n",
      "[17]\tvalid_0's auc: 0.626539\n",
      "[18]\tvalid_0's auc: 0.626725\n",
      "[19]\tvalid_0's auc: 0.626963\n",
      "[20]\tvalid_0's auc: 0.626795\n",
      "[21]\tvalid_0's auc: 0.627469\n",
      "[22]\tvalid_0's auc: 0.62764\n",
      "[23]\tvalid_0's auc: 0.627704\n",
      "[24]\tvalid_0's auc: 0.627811\n",
      "[25]\tvalid_0's auc: 0.627576\n",
      "[26]\tvalid_0's auc: 0.627655\n",
      "[27]\tvalid_0's auc: 0.627856\n",
      "[28]\tvalid_0's auc: 0.628052\n",
      "[29]\tvalid_0's auc: 0.628339\n",
      "[30]\tvalid_0's auc: 0.628477\n",
      "[31]\tvalid_0's auc: 0.628793\n",
      "[32]\tvalid_0's auc: 0.628979\n",
      "[33]\tvalid_0's auc: 0.629173\n",
      "[34]\tvalid_0's auc: 0.629431\n",
      "[35]\tvalid_0's auc: 0.62975\n",
      "[36]\tvalid_0's auc: 0.630071\n",
      "[37]\tvalid_0's auc: 0.630283\n",
      "[38]\tvalid_0's auc: 0.63032\n",
      "[39]\tvalid_0's auc: 0.630353\n",
      "[40]\tvalid_0's auc: 0.630623\n",
      "[41]\tvalid_0's auc: 0.630732\n",
      "[42]\tvalid_0's auc: 0.630771\n",
      "[43]\tvalid_0's auc: 0.630999\n",
      "[44]\tvalid_0's auc: 0.631117\n",
      "[45]\tvalid_0's auc: 0.631126\n",
      "[46]\tvalid_0's auc: 0.631406\n",
      "[47]\tvalid_0's auc: 0.631612\n",
      "[48]\tvalid_0's auc: 0.631727\n",
      "[49]\tvalid_0's auc: 0.631976\n",
      "[50]\tvalid_0's auc: 0.631959\n",
      "[51]\tvalid_0's auc: 0.632104\n",
      "[52]\tvalid_0's auc: 0.632276\n",
      "[53]\tvalid_0's auc: 0.63257\n",
      "[54]\tvalid_0's auc: 0.632626\n",
      "[55]\tvalid_0's auc: 0.632764\n",
      "[56]\tvalid_0's auc: 0.632802\n",
      "[57]\tvalid_0's auc: 0.632885\n",
      "[58]\tvalid_0's auc: 0.633132\n",
      "[59]\tvalid_0's auc: 0.633328\n",
      "[60]\tvalid_0's auc: 0.633569\n",
      "[61]\tvalid_0's auc: 0.633738\n",
      "[62]\tvalid_0's auc: 0.633982\n",
      "[63]\tvalid_0's auc: 0.634107\n",
      "[64]\tvalid_0's auc: 0.634084\n",
      "[65]\tvalid_0's auc: 0.634329\n",
      "[66]\tvalid_0's auc: 0.634321\n",
      "[67]\tvalid_0's auc: 0.634413\n",
      "[68]\tvalid_0's auc: 0.634525\n",
      "[69]\tvalid_0's auc: 0.634539\n",
      "[70]\tvalid_0's auc: 0.634695\n",
      "[71]\tvalid_0's auc: 0.6348\n",
      "[72]\tvalid_0's auc: 0.634799\n",
      "[73]\tvalid_0's auc: 0.634939\n",
      "[74]\tvalid_0's auc: 0.635122\n",
      "[75]\tvalid_0's auc: 0.635231\n",
      "[76]\tvalid_0's auc: 0.635235\n",
      "[77]\tvalid_0's auc: 0.635242\n",
      "[78]\tvalid_0's auc: 0.635384\n",
      "[79]\tvalid_0's auc: 0.635493\n",
      "[80]\tvalid_0's auc: 0.635577\n",
      "[81]\tvalid_0's auc: 0.63578\n",
      "[82]\tvalid_0's auc: 0.635826\n",
      "[83]\tvalid_0's auc: 0.636014\n",
      "[84]\tvalid_0's auc: 0.635987\n",
      "[85]\tvalid_0's auc: 0.636032\n",
      "[86]\tvalid_0's auc: 0.63617\n",
      "[87]\tvalid_0's auc: 0.636248\n",
      "[88]\tvalid_0's auc: 0.636338\n",
      "[89]\tvalid_0's auc: 0.63646\n",
      "[90]\tvalid_0's auc: 0.636447\n",
      "[91]\tvalid_0's auc: 0.636572\n",
      "[92]\tvalid_0's auc: 0.636585\n",
      "[93]\tvalid_0's auc: 0.636527\n",
      "[94]\tvalid_0's auc: 0.636677\n",
      "[95]\tvalid_0's auc: 0.636836\n",
      "[96]\tvalid_0's auc: 0.636843\n",
      "[97]\tvalid_0's auc: 0.636923\n",
      "[98]\tvalid_0's auc: 0.636938\n",
      "[99]\tvalid_0's auc: 0.636903\n",
      "[100]\tvalid_0's auc: 0.636933\n",
      "[101]\tvalid_0's auc: 0.636958\n",
      "[102]\tvalid_0's auc: 0.63696\n",
      "[103]\tvalid_0's auc: 0.637042\n",
      "[104]\tvalid_0's auc: 0.637031\n",
      "[105]\tvalid_0's auc: 0.636949\n",
      "[106]\tvalid_0's auc: 0.636958\n",
      "[107]\tvalid_0's auc: 0.636902\n",
      "[108]\tvalid_0's auc: 0.636944\n",
      "[109]\tvalid_0's auc: 0.63686\n",
      "[110]\tvalid_0's auc: 0.636822\n",
      "[111]\tvalid_0's auc: 0.636885\n",
      "[112]\tvalid_0's auc: 0.636997\n",
      "[113]\tvalid_0's auc: 0.637092\n",
      "[114]\tvalid_0's auc: 0.637097\n",
      "[115]\tvalid_0's auc: 0.637102\n",
      "[116]\tvalid_0's auc: 0.637211\n",
      "[117]\tvalid_0's auc: 0.637222\n",
      "[118]\tvalid_0's auc: 0.637438\n",
      "[119]\tvalid_0's auc: 0.637382\n",
      "[120]\tvalid_0's auc: 0.637293\n",
      "[121]\tvalid_0's auc: 0.637327\n",
      "[122]\tvalid_0's auc: 0.637417\n",
      "[123]\tvalid_0's auc: 0.637395\n",
      "[124]\tvalid_0's auc: 0.637443\n",
      "[125]\tvalid_0's auc: 0.6375\n",
      "[126]\tvalid_0's auc: 0.637465\n",
      "[127]\tvalid_0's auc: 0.637482\n",
      "[128]\tvalid_0's auc: 0.637491\n",
      "[129]\tvalid_0's auc: 0.637649\n",
      "[130]\tvalid_0's auc: 0.637734\n",
      "[131]\tvalid_0's auc: 0.637837\n",
      "[132]\tvalid_0's auc: 0.637942\n",
      "[133]\tvalid_0's auc: 0.637981\n",
      "[134]\tvalid_0's auc: 0.637959\n",
      "[135]\tvalid_0's auc: 0.637943\n",
      "[136]\tvalid_0's auc: 0.638003\n",
      "[137]\tvalid_0's auc: 0.63786\n",
      "[138]\tvalid_0's auc: 0.637899\n",
      "[139]\tvalid_0's auc: 0.63785\n",
      "[140]\tvalid_0's auc: 0.637841\n",
      "[141]\tvalid_0's auc: 0.63793\n",
      "[142]\tvalid_0's auc: 0.637898\n",
      "[143]\tvalid_0's auc: 0.637881\n",
      "[144]\tvalid_0's auc: 0.637897\n",
      "[145]\tvalid_0's auc: 0.637866\n",
      "[146]\tvalid_0's auc: 0.637825\n",
      "[147]\tvalid_0's auc: 0.637797\n",
      "[148]\tvalid_0's auc: 0.637755\n",
      "[149]\tvalid_0's auc: 0.637853\n",
      "[150]\tvalid_0's auc: 0.637866\n",
      "[151]\tvalid_0's auc: 0.637864\n",
      "[152]\tvalid_0's auc: 0.637937\n",
      "[153]\tvalid_0's auc: 0.637987\n",
      "[154]\tvalid_0's auc: 0.637986\n",
      "[155]\tvalid_0's auc: 0.637893\n",
      "[156]\tvalid_0's auc: 0.637919\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.638003\n",
      "{'auc': 0.6380025131414137}\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 8\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.7383334636688232 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: driver-training_1590531244_e6526452\n",
      "Web View: https://ml.azure.com/experiments/driver-training/runs/driver-training_1590531244_e6526452?wsid=/subscriptions/b4f30574-19b5-4753-926d-877888e82fc4/resourcegroups/oh-dsdata-data/workspaces/team5ws\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'driver-training_1590531244_e6526452',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-05-26T22:14:13.144412Z',\n",
       " 'endTimeUtc': '2020-05-26T22:14:34.532386Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': '22d32282-5a10-4924-81d5-40764f9bb593'},\n",
       " 'inputDatasets': [],\n",
       " 'runDefinition': {'script': 'driver_training.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'environment': {'name': 'Experiment driver-training Environment',\n",
       "   'version': 'Autosave_2020-05-26T17:43:28Z_e5477e2b',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults']},\n",
       "      'scikit-learn',\n",
       "      'lightgbm'],\n",
       "     'name': 'azureml_06c16b148b04e8226cfe58e6ee379ca1'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'itpCompute': {'configuration': {}}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.driver-training_1590531244_e6526452/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=ggDzUZpeR77ZxEwqPvz7UJi3eTMOw%2Bb9hPx80GyoRzg%3D&st=2020-05-26T22%3A04%3A35Z&se=2020-05-27T06%3A14%3A35Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.driver-training_1590531244_e6526452/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=6lsJfc8uwLjFWsJRrli%2Fu%2B8tloVp2z5PWzda4EN64Uk%3D&st=2020-05-26T22%3A04%3A35Z&se=2020-05-27T06%3A14%3A35Z&sp=r',\n",
       "  'logs/azureml/8_azureml.log': 'https://team5ws3141506676.blob.core.windows.net/azureml/ExperimentRun/dcid.driver-training_1590531244_e6526452/logs/azureml/8_azureml.log?sv=2019-02-02&sr=b&sig=bzHkgRjEE98nMKK8NiBzDhI%2BNupcQWe0jD71wDt5VoM%3D&st=2020-05-26T22%3A04%3A34Z&se=2020-05-27T06%3A14%3A34Z&sp=r'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=training_folder,\n",
    "                      entry_script='driver_training.py',\n",
    "                      compute_target='local',\n",
    "                      conda_packages=['scikit-learn','lightgbm']\n",
    "                      )\n",
    "\n",
    "# Create an experiment\n",
    "experiment_name = 'driver-training'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)\n",
    "\n",
    "# Run the experiment based on the estimator\n",
    "run = experiment.submit(config=estimator)\n",
    "run.wait_for_completion(show_output=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver-training_1590531244_e6526452 {'learning_rate': 0.04, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'sub_feature': 0.7, 'num_leaves': 60, 'min_data': 100, 'verbose': 0, 'min_hessian': 1, 'auc': 0.6380025131414137}\n"
     ]
    }
   ],
   "source": [
    "# Print the resulting metrics\n",
    "metrics = run.get_metrics(recursive=True)\n",
    "for k, v in metrics.items():\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-c5c402ee7418>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-c5c402ee7418>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(metrics.0)\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='team5ws', subscription_id='b4f30574-19b5-4753-926d-877888e82fc4', resource_group='oh-dsdata-data'), name=driver_model.pkl, id=driver_model.pkl:10, version=10, tags={'metrics': \"{'driver-training_1590531244_e6526452': {'learning_rate': 0.04, 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', 'sub_feature': 0.7, 'num_leaves': 60, 'min_data': 100, 'verbose': 0, 'min_hessian': 1, 'auc': 0.6380025131414137}}\"}, properties={})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register the model\n",
    "run.register_model(model_path='outputs/driver_model.pkl', model_name='driver_model.pkl',tags={'metrics': str(metrics)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ca757e84ac33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0.6377511613946426\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "run.tag(\"auc\", \"0.6377511613946426\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.6.9, pytest-5.4.1, py-1.8.0, pluggy-0.13.0\n",
      "rootdir: /mnt/batch/tasks/shared/LS_root/mounts/clusters/devclusterteam5/code\n",
      "plugins: arraydiff-0.3, openfiles-0.4.0, doctestplus-0.4.0, remotedata-0.3.2\n",
      "collected 3 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "driver-training/test_train.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                        [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/nose/importer.py:12\n",
      "  /anaconda/envs/azureml_py36/lib/python3.6/site-packages/nose/importer.py:12: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "    from imp import find_module, load_module, acquire_lock, release_lock\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "\u001b[33m========================= \u001b[32m3 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 1.11s\u001b[0m\u001b[33m =========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest driver-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
